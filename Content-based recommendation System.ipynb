{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2938710c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78c2e646",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recommend:\n",
    "    def __init__(self, \n",
    "                 transaction_df,\n",
    "                 features_df):\n",
    "        self.transaction_df = transaction_df\n",
    "        self.features_df = features_df\n",
    "        self.model = NearestNeighbors(n_neighbors=12)\n",
    "        self.model.fit(self.features_df.iloc[:, 1:-1].to_numpy())\n",
    "        \n",
    "    \n",
    "    def predict(self, centroid):\n",
    "        _, predictions = self.model.kneighbors(centroid.reshape(1, -1))\n",
    "        return predictions\n",
    "    \n",
    "    def find_centroid(self, article_list):\n",
    "        all_features = []\n",
    "        for article in article_list:\n",
    "            if article in self.features_df[\"article_id\"].tolist():\n",
    "                block = self.features_df[self.features_df[\"article_id\"] == article].iloc[:, 1:-1]\n",
    "#                 print(block)\n",
    "                if block.shape[0] > 0:\n",
    "                    all_features.append(block.to_numpy())\n",
    "\n",
    "        all_features = np.concatenate(np.array(all_features))\n",
    "        return np.sum(all_features, axis=0) / all_features.shape[0]\n",
    "            \n",
    "            \n",
    "            \n",
    "    def get_items_from_index(self, index_list):\n",
    "        \n",
    "        predictions_string = \"\"\n",
    "        for idx in index_list:\n",
    "            try:\n",
    "                predictions_string += str(int(feature_df.iloc[idx][\"article_id\"])) + \" \"\n",
    "            except:\n",
    "                pass\n",
    "        return predictions_string.strip()\n",
    "\n",
    "    def generate_recommendations(self, n_customers=5, feature_type=\"\"):\n",
    "        # make predictions for customers in sample_sub_df\n",
    "\n",
    "        transaction_df = self.transaction_df.drop(['t_dat', 'price', 'sales_channel_id'], axis=1)\n",
    "        \n",
    "        customer_group = transaction_df.groupby(\"customer_id\")\n",
    "        \n",
    "        customer_count = 0\n",
    "        results = []\n",
    "        \n",
    "        for name, group in tqdm(customer_group):\n",
    "            if customer_count < n_customers:\n",
    "                if len(group) > 1:\n",
    "                    customer_count += 1\n",
    "                    try:\n",
    "                        group_len = len(group)\n",
    "                        if group_len == 2:\n",
    "                            test_sample = group[\"article_id\"].sample(n=1)\n",
    "#                             print(test_sample)\n",
    "                            group.drop(test_sample.index, inplace=True)\n",
    "                            centroid = self.find_centroid(test_sample.tolist())\n",
    "                            recommendations = self.predict(centroid)\n",
    "                            recommendations = recommendations.tolist()[0]\n",
    "                            recommendations_string = self.get_items_from_index(recommendations[1:2])\n",
    "\n",
    "                            ground_truth_string = \" \".join(group[\"article_id\"].astype(str).tolist())\n",
    "\n",
    "                            results.append([name, recommendations_string, ground_truth_string])\n",
    "\n",
    "                        else:\n",
    "                            if group_len > 12:\n",
    "                                group_len = 12\n",
    "                            n_samples = int(0.4*group_len)\n",
    "                            n_recomm = group_len - n_samples\n",
    "                            test_sample = group[\"article_id\"].sample(n=n_samples)\n",
    "#                             print(test_sample)\n",
    "                            group.drop(test_sample.index, inplace=True)\n",
    "                            centroid = self.find_centroid(test_sample.tolist())\n",
    "                            recommendations = self.predict(centroid)\n",
    "                            recommendations = recommendations.tolist()[0]\n",
    "                            recommendations_string = self.get_items_from_index(recommendations[1:n_recomm+1])\n",
    "\n",
    "                            ground_truth = group.sample(n=n_recomm)\n",
    "                            ground_truth_string = \" \".join(ground_truth[\"article_id\"].astype(str).tolist())\n",
    "                            results.append([name, recommendations_string, ground_truth_string])\n",
    "                    except:\n",
    "                        pass\n",
    "        \n",
    "        results_df = pd.DataFrame(results, columns=['customer_id', 'recommendations', 'ground_truth'])\n",
    "        results_df.to_csv(\"recommendations_\"+ feature_type +\".csv\")\n",
    "        return results_df\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "class evaluate:\n",
    "    def __init__(self, results_df, articles_df, feature_df):\n",
    "        self.results_df = results_df\n",
    "        self.articles_df = articles_df\n",
    "        self.feature_df = feature_df\n",
    "        self.articles_df = self.articles_df[[\"article_id\", \"index_group_name\"]]\n",
    "        \n",
    "    def calc_metrics(self, predictions, recommendations):    \n",
    "        per_customer_index_name_count = 0\n",
    "        per_customer_cosine_similarity_count = 0\n",
    "        \n",
    "        for i in range(len(predictions)):\n",
    "            try:\n",
    "                check_index_group_name_pred = self.articles_df[articles_df[\"article_id\"] == int(predictions[i])][\"index_group_name\"].tolist()\n",
    "                check_index_group_name_recom = self.articles_df[articles_df[\"article_id\"] == int(recommendations[i])][\"index_group_name\"].tolist()\n",
    "                if check_index_group_name_pred[0] == check_index_group_name_recom[0]:\n",
    "                    per_customer_index_name_count += 1\n",
    "\n",
    "                img_pred = self.feature_df[self.feature_df[\"article_id\"] == int(predictions[i])].iloc[:, 1:-1].to_numpy()\n",
    "                img_recom = self.feature_df[self.feature_df[\"article_id\"] == int(recommendations[i])].iloc[:, 1:-1].to_numpy()\n",
    "                if cosine_similarity(img_pred, img_recom) > 0.9:\n",
    "                    per_customer_cosine_similarity_count += 1\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        return per_customer_index_name_count/len(predictions), per_customer_cosine_similarity_count/len(predictions)\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        valid_count = 0\n",
    "        all_customers_index_metric = 0\n",
    "        all_customers_cosine_simialrity = 0\n",
    "        \n",
    "        for (idx, row) in self.results_df.iterrows():\n",
    "            preds = row[\"ground_truth\"].split(\" \")\n",
    "            recoms = row[\"recommendations\"].split(\" \")\n",
    "\n",
    "            if len(preds) == len(recoms):\n",
    "                valid_count += 1\n",
    "                index_metric, similarity = self.calc_metrics(preds, recoms)\n",
    "                all_customers_index_metric += index_metric\n",
    "                all_customers_cosine_simialrity += similarity\n",
    "                \n",
    "                \n",
    "        return all_customers_cosine_simialrity/valid_count, all_customers_index_metric/valid_count            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f10284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## bottleneck, run this cell only once before calling the object. Don't run unless runtime fails\n",
    "articles_path = \"C:/Users/ojubh\\/Desktop/SEMESTER 2/Deep Learning/Final_Project/data/articles.csv\"\n",
    "transaction_path = \"C:/Users/ojubh\\/Desktop/SEMESTER 2/Deep Learning/Final_Project/data/transactions_train.csv\"\n",
    "features_path = \"C:/Users/ojubh\\/Desktop/SEMESTER 2/Deep Learning/Final_Project/data/text_embeddings_final.csv\"\n",
    "\n",
    "transaction_df = pd.read_csv(transaction_path)\n",
    "feature_df = pd.read_csv(features_path)\n",
    "articles_df = pd.read_csv(articles_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f8d5c90b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1362281/1362281 [02:54<00:00, 7796.85it/s] \n"
     ]
    }
   ],
   "source": [
    "recommend = Recommend(transaction_df, feature_df)\n",
    "recommendations = recommend.generate_recommendations(n_customers=2000, feature_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ee2dadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_metrics, category_metric = evaluate(recommendations, articles_df, feature_df).get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "450935e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_embds = pd.read_csv(\"C:/Users/ojubh\\/Desktop/SEMESTER 2/Deep Learning/Final_Project/data/visual_embeddings_final.csv\")\n",
    "text_embds = pd.read_csv(\"C:/Users/ojubh\\/Desktop/SEMESTER 2/Deep Learning/Final_Project/data/text_embeddings_final.csv\")\n",
    "merged = image_embds.merge(text_embds, on=\"article_id\", how=\"inner\")\n",
    "merged.drop(['Unnamed: 0_y'], axis=1, inplace=True)\n",
    "article_id = merged.pop(\"article_id\")\n",
    "merged.insert(513, \"article_id\", article_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
